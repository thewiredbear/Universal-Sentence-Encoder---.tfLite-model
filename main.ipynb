{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-02 21:41:39.422542: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SavedModel from: /Users/ghazalsden/Desktop/KanKan/vDS/Gemma3n_Hackathon/github/USE_tflite/Universal-Sentence-Encoder---.tfLite-model/universal-sentence-encoder-tensorflow1-lite-v2/saved_model.pb\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: universal-sentence-encoder-tensorflow1-lite-v2/saved_model.pb/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoading SavedModel from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos.path.abspath(SAVED_MODEL_PATH)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# --- Step 1: Create a TFLiteConverter object from the SavedModel ---\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# This is the core function that loads the TensorFlow graph.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m converter = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlite\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFLiteConverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSAVED_MODEL_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# --- Step 2: Configure the Converter ---\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Apply default optimizations to reduce model size and latency.\u001b[39;00m\n\u001b[32m     15\u001b[39m converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/KanKan/vDS/Gemma3n_Hackathon/github/USE_tflite/venv/lib/python3.11/site-packages/tensorflow/lite/python/lite.py:2118\u001b[39m, in \u001b[36mTFLiteConverterV2.from_saved_model\u001b[39m\u001b[34m(cls, saved_model_dir, signature_keys, tags)\u001b[39m\n\u001b[32m   2115\u001b[39m   tags = \u001b[38;5;28mset\u001b[39m([_tag_constants.SERVING])\n\u001b[32m   2117\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context.eager_mode():\n\u001b[32m-> \u001b[39m\u001b[32m2118\u001b[39m   saved_model = \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43msaved_model_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signature_keys:\n\u001b[32m   2120\u001b[39m   signature_keys = \u001b[38;5;28mlist\u001b[39m(saved_model.signatures.keys())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/KanKan/vDS/Gemma3n_Hackathon/github/USE_tflite/venv/lib/python3.11/site-packages/tensorflow/python/saved_model/load.py:912\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(export_dir, tags, options)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(export_dir, os.PathLike):\n\u001b[32m    911\u001b[39m   export_dir = os.fspath(export_dir)\n\u001b[32m--> \u001b[39m\u001b[32m912\u001b[39m result = \u001b[43mload_partial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mroot\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/KanKan/vDS/Gemma3n_Hackathon/github/USE_tflite/venv/lib/python3.11/site-packages/tensorflow/python/saved_model/load.py:1016\u001b[39m, in \u001b[36mload_partial\u001b[39m\u001b[34m(export_dir, filters, tags, options)\u001b[39m\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tags, \u001b[38;5;28mset\u001b[39m):\n\u001b[32m   1012\u001b[39m   \u001b[38;5;66;03m# Supports e.g. tags=SERVING and tags=[SERVING]. Sets aren't considered\u001b[39;00m\n\u001b[32m   1013\u001b[39m   \u001b[38;5;66;03m# sequences for nest.flatten, so we put those through as-is.\u001b[39;00m\n\u001b[32m   1014\u001b[39m   tags = nest.flatten(tags)\n\u001b[32m   1015\u001b[39m saved_model_proto, debug_info = (\n\u001b[32m-> \u001b[39m\u001b[32m1016\u001b[39m     \u001b[43mloader_impl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse_saved_model_with_debug_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1018\u001b[39m loader = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1019\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(saved_model_proto.meta_graphs) == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m   1020\u001b[39m     saved_model_proto.meta_graphs[\u001b[32m0\u001b[39m].HasField(\u001b[33m\"\u001b[39m\u001b[33mobject_graph_def\u001b[39m\u001b[33m\"\u001b[39m)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/KanKan/vDS/Gemma3n_Hackathon/github/USE_tflite/venv/lib/python3.11/site-packages/tensorflow/python/saved_model/loader_impl.py:59\u001b[39m, in \u001b[36mparse_saved_model_with_debug_info\u001b[39m\u001b[34m(export_dir)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse_saved_model_with_debug_info\u001b[39m(export_dir):\n\u001b[32m     47\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Reads the savedmodel as well as the graph debug info.\u001b[39;00m\n\u001b[32m     48\u001b[39m \n\u001b[32m     49\u001b[39m \u001b[33;03m  Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m \u001b[33;03m    parsed. Missing graph debug info file is fine.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m   saved_model = \u001b[43mparse_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m   debug_info_path = file_io.join(\n\u001b[32m     62\u001b[39m       path_helpers.get_debug_dir(export_dir),\n\u001b[32m     63\u001b[39m       constants.DEBUG_INFO_FILENAME_PB)\n\u001b[32m     64\u001b[39m   debug_info = graph_debug_info_pb2.GraphDebugInfo()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/KanKan/vDS/Gemma3n_Hackathon/github/USE_tflite/venv/lib/python3.11/site-packages/tensorflow/python/saved_model/loader_impl.py:119\u001b[39m, in \u001b[36mparse_saved_model\u001b[39m\u001b[34m(export_dir)\u001b[39m\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot parse file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_to_pbtxt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[32m    120\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSavedModel file does not exist at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexport_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mos.path.sep\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    121\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mconstants.SAVED_MODEL_FILENAME_PBTXT\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m|\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    122\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstants.SAVED_MODEL_FILENAME_PB\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m saved_model\n",
      "\u001b[31mOSError\u001b[39m: SavedModel file does not exist at: universal-sentence-encoder-tensorflow1-lite-v2/saved_model.pb/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Configuration ---\n",
    "# Path to the unzipped SavedModel directory from Kaggle\n",
    "SAVED_MODEL_PATH = 'universal-sentence-encoder-tensorflow1-lite-v2' \n",
    "# Path where the output .tflite file will be saved\n",
    "TFLITE_MODEL_PATH = 'use_embedding_model.tflite'\n",
    "\n",
    "print(f\"Loading SavedModel from: {os.path.abspath(SAVED_MODEL_PATH)}\")\n",
    "\n",
    "# --- Step 1: Create a TFLiteConverter object from the SavedModel ---\n",
    "# This is the core function that loads the TensorFlow graph.\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_PATH)\n",
    "\n",
    "# --- Step 2: Configure the Converter ---\n",
    "# Apply default optimizations to reduce model size and latency.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# This is a CRITICAL step. The USE model contains operations that are not\n",
    "# part of the standard TFLite library. This flag tells the converter to\n",
    "# include the necessary TensorFlow operators in the final model. Without this,\n",
    "# the conversion will fail or the model won't run in Flutter.\n",
    "converter.target_spec.supported_ops = [\n",
    "  tf.lite.OpsSet.TFLITE_BUILTINS, # Enable default TFLite ops.\n",
    "  tf.lite.OpsSet.SELECT_TF_OPS    # Enable TensorFlow ops.\n",
    "]\n",
    "\n",
    "print(\"Starting TFLite conversion...\")\n",
    "\n",
    "# --- Step 3: Run the Conversion ---\n",
    "# This process analyzes the graph and converts it to the TFLite format.\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "print(\"Conversion successful!\")\n",
    "\n",
    "# --- Step 4: Save the Converted Model to a File ---\n",
    "with open(TFLITE_MODEL_PATH, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"âœ… Model saved successfully to: {os.path.abspath(TFLITE_MODEL_PATH)}\")\n",
    "print(f\"File size: {os.path.getsize(TFLITE_MODEL_PATH) / (1024*1024):.2f} MB\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
